<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Community Health Toolkit – 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/</link><description>Recent content in 4.x on Community Health Toolkit</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://docs.communityhealthtoolkit.org/hosting/4.x/index.xml" rel="self" type="application/rss+xml"/><item><title>Hosting: Migration from CHT 3.x to CHT 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/data-migration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/data-migration/</guid><description>
&lt;p>The hosting architecture differs entirely between CHT-Core 3.x and CHT-Core 4.x. Migrating data from an existing instance running CHT 3.x requires a few manual steps.
This guide will present the required steps while using a migration helping tool, called &lt;code>couchdb-migration&lt;/code>. This tool interfaces with CouchDb, to update shard maps and database metadata.
By the end of this guide, your CHT-Core 3.x CouchDb will be down and CHT-Core 4.x ready to be used.
Using this tool is not required, and the same result can be achieved by calling CouchDb endpoints directly. &lt;a href="https://docs.couchdb.org/en/stable/cluster/sharding.html#moving-a-shard">Consult CouchDB documentation for details about moving shards&lt;/a>.&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
If after upgrading you get an error, &lt;code>Cannot convert undefined or null to object&lt;/code> - please see &lt;a href="https://github.com/medic/cht-core/issues/8040">issue #8040&lt;/a> for a work around. This only affects CHT 4.0.0, 4.0.1, 4.1.0 and 4.1.1. It was fixed in CHT 4.2.0.
&lt;/div>
&lt;h3 id="1-install-cht-data-migration-tool">1. Install CHT data migration tool&lt;/h3>
&lt;p>Open your terminal and run these commands. They will create a new directory, download a docker compose file and download the required docker image.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o ./docker-compose.yml https://raw.githubusercontent.com/medic/couchdb-migration/main/docker-compose.yml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>For the following steps, the tool needs access to your CouchDb installation. To allow this access, you will need to provide a URL to your CouchDB installation that includes authentication.
If your installation exposes a different port for CouchDb cluster API endpoints, please export that port.
If running against an installation of &lt;code>MedicOS&lt;/code>, please make sure that the protocol of the URL is &lt;code>https&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">COUCH_URL&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>http&lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>s&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>://&amp;lt;authentication&amp;gt;@&amp;lt;host-ip&amp;gt;:&amp;lt;port&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>For simplicity, you could store these required values in an &lt;code>.env&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cat &amp;gt; &lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">HOME&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchdb-migration/.env &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCH_URL=http(s)://&amp;lt;authentication&amp;gt;@&amp;lt;host-ip&amp;gt;:&amp;lt;port&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-prepare-cht-core-3x-installation-for-upgrading">2. Prepare CHT-Core 3.x installation for upgrading&lt;/h3>
&lt;p>Backup your data! If you encounter any problems executing the instructions of this guide, you should be able to restore your CHT 3X instance using the backup data.
&lt;a href="https://docs.communityhealthtoolkit.org/hosting/3.x/self-hosting/#backup">Consult information about backups for details&lt;/a>.
Ensure no changes happen to your CouchDB data in your CHT 3.x server after you have begun the migration process.&lt;/p>
&lt;p>To minimize downtime when upgrading, it&amp;rsquo;s advised to prepare the 3.x installation for the 4.x upgrade, and pre-index all views that are required by 4.x.&lt;/p>
&lt;p>The migration tool provides a command which will download all 4.x views to your 3.x CouchDb, and initiate view indexing. &lt;code>&amp;lt;desired CHT version&amp;gt;&lt;/code> is any version at or above &lt;code>4.0.0&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration pre-index-views &amp;lt;desired CHT version&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once view indexing is finished, proceed with the next step.&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
If this step is omitted, 4.x API will fail to respond to requests until all views are indexed. Depending on the size of the database, this could take many hours, or even days.
&lt;/div>
&lt;h3 id="3-save-existent-couchdb-configuration">3. Save existent CouchDb configuration&lt;/h3>
&lt;p>Some CouchDb configuration values must be ported from existent CouchDb to the 4.x installation. Store them in a safe location before shutting down 3.x CouchDb.
Use the migration tool to obtain these values:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration get-env
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="a-couchdb-secret">a) CouchDB secret&lt;/h5>
&lt;p>Used in encrypting all CouchDb passwords and session tokens.&lt;/p>
&lt;h5 id="b-couchdb-server-uuid">b) CouchDb server uuid&lt;/h5>
&lt;p>Used in generating replication checkpointer documents, which track where replication progress between every client and the server, and ensure that clients don&amp;rsquo;t re-download or re-upload documents.&lt;/p>
&lt;h3 id="4-locate-and-make-a-copy-of-your-couchdb-data-folder">4. Locate and make a copy of your CouchDb Data folder&lt;/h3>
&lt;p>a) If running in MedicOS, &lt;a href="https://docs.communityhealthtoolkit.org/hosting/3.x/self-hosting/#backup">CouchDb data folder&lt;/a> can be found at &lt;code>/srv/storage/medic-core/couchdb/data&lt;/code>.&lt;/p>
&lt;p>b) If running a custom installation of CouchDb, data would be typically stored at &lt;code>/opt/couchdb/data&lt;/code>.&lt;/p>
&lt;h3 id="5-stop-your-3x-couchdb--cht-core-installation-and-launch-4x-couchdb-installation">5. Stop your 3.x CouchDb / CHT-Core installation and launch 4.x CouchDb installation&lt;/h3>
&lt;p>Depending on your project scalability needs and technical possibilities, you must decide whether you will deploy CouchDb in a single node or in a cluster with multiple nodes.
Please consult this guide about clustering and horizontal scalability to make an informed decision. &lt;insert link>&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
You can start with single node and then change to a cluster. This involves running the migration tool again to distribute shards from the existent node to the new nodes.
&lt;/div>
&lt;p>Depending on your choice, follow the instructions that match your deployment below:&lt;/p>
&lt;h4 id="single-node">Single node&lt;/h4>
&lt;p>a) Download 4.x single-node CouchDb docker-compose file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p ~/couchdb-single/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-single/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o ./docker-compose.yml https://staging.dev.medicmobile.org/_couch/builds_4/medic:medic:&amp;lt;desired CHT version&amp;gt;/docker-compose/cht-couchdb.yml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>a) Make a copy of the 3.x CouchDb data folder from &lt;strong>step 4&lt;/strong>.&lt;/p>
&lt;p>b) Set the correct environment variables:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cat &amp;gt; &lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">HOME&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchdb-single/.env &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_USER=&amp;lt;admin&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_PASSWORD=&amp;lt;password&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_SECRET=&amp;lt;COUCHDB_SECRET from step 3&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_UUID=&amp;lt;COUCHDB_UUID from step 3&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_DATA=&amp;lt;absolute path to folder created in step 5.a&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>c) Start 4.x CouchDb.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-single/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose up -d
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>d) Update &lt;code>couchdb-migration&lt;/code> environment variables. Depending on your setup, it&amp;rsquo;s possible you will need to update &lt;code>CHT_NETWORK&lt;/code> and &lt;code>COUCH_URL&lt;/code> to match the newly started 4.x CouchDb.
From this point on, the &lt;code>couchdb-migration&lt;/code> container should connect to the same docker network as your CouchDb installation, in order to access APIs that are only available on protected ports. Correctly setting &lt;code>CHT_NETWORK&lt;/code> is required for the next steps to succeed.
To get the correct &lt;code>docker-network-name&lt;/code> and &lt;code>docker-service-name&lt;/code>, you can use &lt;code>docker network ls&lt;/code> to list all networks and &lt;code>docker network inspect &amp;lt;docker-network-name&amp;gt;&lt;/code> to get the name of the CouchDb container that exists in this network.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cat &amp;gt; &lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">HOME&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchdb-migration/.env &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">CHT_NETWORK=&amp;lt;docker-network-name&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCH_URL=http://&amp;lt;authentication&amp;gt;@&amp;lt;docker-container-name&amp;gt;:&amp;lt;port&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>e) Check that &lt;code>couchdb-migration&lt;/code> can connect to the CouchDb instance and that CouchDb is running. You&amp;rsquo;ll know it is working when the &lt;code>docker-compose&lt;/code> call exits without errors and logs &lt;code>CouchDb is Ready&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration check-couchdb-up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>f) Change metadata to match the new CouchDb node&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration move-node
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>g) Run the &lt;code>verify&lt;/code> command to check whether the migration was successful.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration verify
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If all checks pass, you should see a message &lt;code>Migration verification passed&lt;/code>. It is then safe to proceed with starting CHT-Core 4.x, using the same environment variables you saved in &lt;code>~/couchdb-single/.env&lt;/code>.&lt;/p>
&lt;p>h) &lt;a href="#6-cleanup">Remove unnecessary containers&lt;/a>.&lt;/p>
&lt;h4 id="multi-node">Multi node&lt;/h4>
&lt;p>a) Download 4.x clustered CouchDb docker-compose file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p ~/couchdb-cluster/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-cluster/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o ./docker-compose.yml https://staging.dev.medicmobile.org/_couch/builds_4/medic:medic:&amp;lt;desired CHT version&amp;gt;/docker-compose/cht-couchdb-clustered.yml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>b) Create a data folder for every one of the CouchDb nodes.
If you were going to a 3 cluster node, this would be:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p ~/couchdb-data/main
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir -p ~/couchdb-data/secondary1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir -p ~/couchdb-data/secondary2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>c) Copy the 3.x CouchDb data folder into &lt;code>~/couchdb-data/main&lt;/code>, which will be your main CouchDb node. This main node will create your cluster and the other secondary nodes will be added to it. In &lt;code>main&lt;/code>&amp;rsquo;s environment variable file, define &lt;code>CLUSTER_PEER_IPS&lt;/code>. In all other secondary nodes, declare the &lt;code>COUCHDB_SYNC_ADMINS_NODE&lt;/code> variable instead.&lt;/p>
&lt;p>d) Create a &lt;code>shards&lt;/code> and a &lt;code>.shards&lt;/code> directory in every secondary node folder.&lt;/p>
&lt;p>e) Set the correct environment variables:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cat &amp;gt; &lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">HOME&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchdb-cluster/.env &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_USER=&amp;lt;admin&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_PASSWORD=&amp;lt;password&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_SECRET=&amp;lt;COUCHDB_SECRET from step 3&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCHDB_UUID=&amp;lt;COUCHDB_UUID from step 3&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">DB1_DATA=&amp;lt;absolute path to main folder created in step 5.a&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">DB2_DATA=&amp;lt;absolute path to secondary1 folder created in step 5.a&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">DB3_DATA=&amp;lt;absolute path to secondary2 folder created in step 5.a&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>f) Start 4.x CouchDb.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-cluster/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose up -d
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>g) Update &lt;code>couchdb-migration&lt;/code> environment variables. Depending on your setup, it&amp;rsquo;s possible you will need to update &lt;code>CHT_NETWORK&lt;/code> and &lt;code>COUCH_URL&lt;/code> to match the newly started 4.x CouchDb.
From this point on, the &lt;code>couchdb-migration&lt;/code> container should connect to the same docker network as your CouchDb installation, in order to access APIs that are only available on protected ports. Correctly setting &lt;code>CHT_NETWORK&lt;/code> is required for the next steps to succeed.
To get the correct &lt;code>docker-network-name&lt;/code> and &lt;code>docker-service-name&lt;/code>, you can use &lt;code>docker network ls&lt;/code> to list all networks and &lt;code>docker network inspect &amp;lt;docker-network-name&amp;gt;&lt;/code> to get the name of the CouchDb container that exists in this network.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>cat &amp;gt; &lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">HOME&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchdb-migration/.env &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">CHT_NETWORK=&amp;lt;docker-network-name&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">COUCH_URL=http://&amp;lt;authentication&amp;gt;@&amp;lt;docker-container-name&amp;gt;:&amp;lt;port&amp;gt;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>h) Check that &lt;code>couchdb-migration&lt;/code> can connect to the CouchDb instance and that CouchDb is running. You&amp;rsquo;ll know it is working when the &lt;code>docker-compose&lt;/code> call exits without errors and logs &lt;code>CouchDb Cluster is Ready&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration check-couchdb-up &amp;lt;number-of-nodes&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>i) Generate the shard distribution matrix and get instructions for final shard locations.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/couchdb-migration/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">shard_matrix&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>docker-compose run couch-migration generate-shard-distribution-matrix&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration shard-move-instructions &lt;span style="color:#000">$shard_matrix&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>j) Follow the instructions from the step above and move the shard files to the correct location, according to the shard distribution matrix. This is a manual step that requires to physically move data around on disk.&lt;/p>
&lt;p>Example of moving one shard from one node to another:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>/couchdb_data_main
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /.delete
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /_dbs.couch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /_nodes.couch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /_users.couch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /.shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /00000000-15555554
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /2aaaaaaa-3ffffffe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /3fffffff-55555553
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /6aaaaaa9-7ffffffd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /7ffffffe-95555552
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /15555555-2aaaaaa9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /55555554-6aaaaaa8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /95555553-aaaaaaa7
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /00000000-15555554
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /2aaaaaaa-3ffffffe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /3fffffff-55555553
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /6aaaaaa9-7ffffffd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /7ffffffe-95555552
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /15555555-2aaaaaa9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /55555554-6aaaaaa8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /95555553-aaaaaaa7
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/couchdb_data_secondary
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /.shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /shards
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After moving two shards: &lt;code>55555554-6aaaaaa8&lt;/code> and &lt;code>6aaaaaa9-7ffffffd&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>/couchdb_data_main
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /.delete
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /_dbs.couch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /_nodes.couch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /_users.couch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /.shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /00000000-15555554
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /2aaaaaaa-3ffffffe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /3fffffff-55555553
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /7ffffffe-95555552
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /15555555-2aaaaaa9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /95555553-aaaaaaa7
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /00000000-15555554
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /2aaaaaaa-3ffffffe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /3fffffff-55555553
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /7ffffffe-95555552
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /15555555-2aaaaaa9
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /95555553-aaaaaaa7
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/couchdb_data_secondary
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /.shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /6aaaaaa9-7ffffffd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /55555554-6aaaaaa8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /shards
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /6aaaaaa9-7ffffffd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> /55555554-6aaaaaa8
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>k) Change metadata to match the new shard distribution. We declared &lt;code>$shard_matrix&lt;/code> in step &amp;ldquo;g&amp;rdquo; above, so it is still set now:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration move-shards &lt;span style="color:#000">$shard_matrix&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>l) Remove old node from the cluster:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration remove-node couchdb@127.0.0.1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>j) Run the &lt;code>verify&lt;/code> command to check whether the migration was successful.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker-compose run couch-migration verify
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If all checks pass, you should see a message &lt;code>Migration verification passed&lt;/code>. It is then safe to proceed with starting CHT-Core 4.x, using the same environment variables you saved in &lt;code>~/couchdb-cluster/.env&lt;/code>.&lt;/p>
&lt;p>k) &lt;a href="#6-cleanup">Remove unnecessary containers&lt;/a>.&lt;/p>
&lt;h3 id="6-cleanup">6. Cleanup&lt;/h3>
&lt;p>It&amp;rsquo;s very important to remove temporary containers that were used during migration and containers that deployed the previous CHT-Core 3.x installation. Only follow this step after making sure your CHT-Core 4.x installation is ready and can be used.&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Warning&lt;/h4>
Even if these containers are stopped, depending on their configuration, they could restart when the Docker engine is restarted, for example on system reboot.
&lt;/div>
&lt;h5 id="risks-for-not-removing-containers-include">Risks for not removing containers include&lt;/h5>
&lt;ul>
&lt;li>resource contention - where your new CHT installation might not have access to certain resources (for example network ports) because they are already used.&lt;/li>
&lt;li>data corruption - when multiple CouchDb installations are accessing the same data source.&lt;/li>
&lt;li>data loss - when multiple CouchDb installation are exposing on the same port.&lt;/li>
&lt;/ul>
&lt;p>To get a list of all containers run:&lt;/p>
&lt;pre tabindex="0">&lt;code>docker ps -a
&lt;/code>&lt;/pre>&lt;p>From this list, you should find the names for :&lt;/p>
&lt;ul>
&lt;li>containers that ran CHT-Core 3.x, likely named &lt;code>medic-os&lt;/code> and &lt;code>haproxy&lt;/code>.&lt;/li>
&lt;li>temporary single node CouchDb containers, likely named &lt;code>couchdb-single-couchdb-1&lt;/code>&lt;/li>
&lt;li>temporary clustered CouchDb containers, likely named &lt;code>couchdb-cluster-couchdb-2.local-1&lt;/code>, &lt;code>couchdb-cluster-couchdb-1.local-1&lt;/code> and &lt;code>couchdb-cluster-couchdb-3.local-1&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>To remove containers, run these commands:&lt;/p>
&lt;pre tabindex="0">&lt;code>docker stop &amp;lt;container&amp;gt; &amp;lt;container&amp;gt; &amp;lt;container&amp;gt;
docker rm &amp;lt;container&amp;gt; &amp;lt;container&amp;gt; &amp;lt;container&amp;gt;
&lt;/code>&lt;/pre></description></item><item><title>Hosting: Self Hosting in CHT 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/</guid><description>
&lt;h1 id="recommendations-and-considerations">Recommendations and considerations&lt;/h1>
&lt;h2 id="multi-vs-single-node-couchdb-requirements">Multi vs Single node couchdb requirements&lt;/h2>
&lt;p>For smaller deployments a &lt;a href="https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/single-node/">single node CouchDB&lt;/a> instance can be used, for larger deployments a &lt;a href="https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/multiple-nodes/">multi-node CouchDB&lt;/a> cluster is generally recommended&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Consideration&lt;/th>
&lt;th>&lt;a href="https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/single-node/">Single node CouchDB&lt;/a>&lt;/th>
&lt;th>&lt;a href="https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/multiple-nodes/">Multi-node clustered CouchDB&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Less than
4 000 users&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>More than
4 000 users&lt;/td>
&lt;td>&lt;span title="No">❌&lt;/span>&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Less than
10 000 documents per day&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>More than
10 000 documents per day&lt;/td>
&lt;td>&lt;span title="No">❌&lt;/span>&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Seamless upgrade with multi-node docker compose&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;td>&lt;span title="No">❌&lt;/span>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Seamless upgrade with multi-node kubernetes/k3s&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="cloud-provider-vs-bare-metal">Cloud provider vs Bare metal&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Consideration&lt;/th>
&lt;th>Cloud provider&lt;/th>
&lt;th>Bare Metal&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Data needs to be in-country&lt;/td>
&lt;td>&lt;span title="No">❌&lt;/span>&lt;/td>
&lt;td>&lt;span title="Yes">✔&lt;/span>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Hosting: App Developer Hosting in CHT 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/app-developer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/app-developer/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>This guide assumes you are a CHT app developer wanting to either run concurrent instances of the CHT, or easily be able to switch between different instances without losing any data while doing so. To do development on the CHT Core Framework itself, see the &lt;a href="https://docs.communityhealthtoolkit.org/contribute/code/core/dev-environment/">development guide&lt;/a>.&lt;/p>
&lt;p>To deploy the CHT 3.x in production, see either &lt;a href="https://docs.communityhealthtoolkit.org/hosting/3.x/ec2-setup-guide/">AWS hosting&lt;/a> or &lt;a href="https://docs.communityhealthtoolkit.org/hosting/3.x/self-hosting/">Self hosting&lt;/a>. 4.x production hosting guides are coming soon!&lt;/p>
&lt;/div>
&lt;h2 id="getting-started">Getting started&lt;/h2>
&lt;p>Be sure to meet the &lt;a href="https://docs.communityhealthtoolkit.org/hosting/requirements/">CHT hosting requirements&lt;/a> first. To avoid conflicts, ensure that all other CHT 4.x instances are stopped. To stop ALL containers, you can use&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker &lt;span style="color:#204a87">kill&lt;/span> &lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>docker ps -q&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After meeting these requirements, create a directory and download the developer YAML files in the directory you want to store them. This example uses &lt;code>~/cht-4-app-developer&lt;/code> as the directory:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir ~/cht-4-app-developer &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#204a87">cd&lt;/span> ~/cht-4-app-developer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o docker-compose.yml https://raw.githubusercontent.com/medic/cht-upgrade-service/main/docker-compose.yml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o cht-core.yml https://staging.dev.medicmobile.org/_couch/builds_4/medic%3Amedic%3Amaster/docker-compose/cht-core.yml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o cht-couchdb.yml https://staging.dev.medicmobile.org/_couch/builds_4/medic%3Amedic%3Amaster/docker-compose/cht-couchdb.yml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You should now have 3 compose files which we can check with &lt;code>ls&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>ls
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cht-core.yml cht-couchdb.yml docker-compose.yml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To start the first developer CHT instance, run &lt;code>docker-compose&lt;/code>, prepending the needed environment variables:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">CHT_COMPOSE_PROJECT_NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>app-devl &lt;span style="color:#000">COUCHDB_SECRET&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>foo &lt;span style="color:#000">DOCKER_CONFIG_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">PWD&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span> &lt;span style="color:#000">COUCHDB_DATA&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">PWD&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchd &lt;span style="color:#000">CHT_COMPOSE_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">PWD&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span> &lt;span style="color:#000">COUCHDB_USER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>medic &lt;span style="color:#000">COUCHDB_PASSWORD&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>password docker-compose up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This may take some minutes to fully start depending on the speed of the internet connection and speed of the host. This is because docker needs to download all the storage layers for all the containers and the CHT needs to run the first run set up. After downloads and setup has completed, the CHT should be accessible on &lt;a href="https://localhost">https://localhost&lt;/a>. You can log in with username &lt;code>medic&lt;/code> and password &lt;code>password&lt;/code>.&lt;/p>
&lt;p>When connecting to a new dev CHT instance for the first time, an error will be shown, &amp;ldquo;Your connection is not private&amp;rdquo; with &lt;code>NET::ERR_CERT_AUTHORITY_INVALID&lt;/code> (see &lt;a href="https://docs.communityhealthtoolkit.org/apps/tutorials/local-setup/privacy.error.png">screenshot&lt;/a>). To get past this, click &amp;ldquo;Advanced&amp;rdquo; and then click &amp;ldquo;Proceed to localhost&amp;rdquo;.&lt;/p>
&lt;h2 id="running-the-nth-cht-instance">Running the Nth CHT instance&lt;/h2>
&lt;p>After running the first instance of the CHT, it&amp;rsquo;s easy to run as many more as are needed. This is achieved by specifying different:&lt;/p>
&lt;ul>
&lt;li>port for &lt;code>HTTP&lt;/code> redirects (&lt;code>CHT_HTTP&lt;/code>)&lt;/li>
&lt;li>port for &lt;code>HTTPS&lt;/code> traffic (&lt;code>NGINX_HTTP_PORT&lt;/code>)&lt;/li>
&lt;li>directory for storing the compose files and CouchDB files&lt;/li>
&lt;/ul>
&lt;p>Assuming you want to start a new project called &lt;code>the_second&lt;/code> and start the instance on &lt;code>HTTP&lt;/code> port &lt;code>8081&lt;/code> and &lt;code>HTTPS&lt;/code> port &lt;code>8443&lt;/code>, we would first create a new directory and download the same files:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir ~/the_second &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#204a87">cd&lt;/span> ~/the_second
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o docker-compose.yml https://raw.githubusercontent.com/medic/cht-upgrade-service/main/docker-compose.yml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o cht-core.yml https://staging.dev.medicmobile.org/_couch/builds_4/medic%3Amedic%3Amaster/docker-compose/cht-core.yml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -s -o cht-couchdb.yml https://staging.dev.medicmobile.org/_couch/builds_4/medic%3Amedic%3Amaster/docker-compose/cht-couchdb.yml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then, we would use the same &lt;code>docker-compose&lt;/code> command as above, but this time specify the ports:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">NGINX_HTTP_PORT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8081&lt;/span> &lt;span style="color:#000">NGINX_HTTPS_PORT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8444&lt;/span> &lt;span style="color:#000">CHT_COMPOSE_PROJECT_NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>app-devl &lt;span style="color:#000">COUCHDB_SECRET&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>foo &lt;span style="color:#000">DOCKER_CONFIG_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">PWD&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span> &lt;span style="color:#000">COUCHDB_DATA&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">PWD&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span>/couchd &lt;span style="color:#000">CHT_COMPOSE_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">${&lt;/span>&lt;span style="color:#000">PWD&lt;/span>&lt;span style="color:#4e9a06">}&lt;/span> &lt;span style="color:#000">COUCHDB_USER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>medic &lt;span style="color:#000">COUCHDB_PASSWORD&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>password docker-compose up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The second instance is now accessible at &lt;a href="https://localhost:8444">https://localhost:8444&lt;/a> and again using username &lt;code>medic&lt;/code> and password &lt;code>password&lt;/code> to login.&lt;/p>
&lt;h2 id="the-env-file">The &lt;code>.env&lt;/code> file&lt;/h2>
&lt;p>Often times it&amp;rsquo;s convenient to use revision control, like GitHub, to store and publish changes in a CHT app. A nice compliment to this is to store the specifics on how to run the &lt;code>docker-compose&lt;/code> command for each app. By using a shared &lt;code>docker-compose&lt;/code> configuration for all developers on the same app, it avoids any port collisions and enables all developers to have a unified configuration.&lt;/p>
&lt;p>Using the above &lt;code>the_second&lt;/code> sample project, we can create a file &lt;code>~/the_second/.env&lt;/code> with this contents:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">NGINX_HTTP_PORT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8081&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">NGINX_HTTPS_PORT&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8444&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">CHT_COMPOSE_PROJECT_NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>second
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">COUCHDB_SECRET&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">DOCKER_CONFIG_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>./
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">COUCHDB_DATA&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>./couchd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">CHT_COMPOSE_PATH&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>./
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">COUCHDB_USER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>medic
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">COUCHDB_PASSWORD&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>password
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now it&amp;rsquo;s easy to boot this environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> ~/the_second
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="switching--concurrent-projects">Switching &amp;amp; concurrent projects&lt;/h2>
&lt;p>The easiest way to switch between projects is to stop the first set of containers and start the second set. Cancel the first project running in the foreground with &lt;code>ctrl + c&lt;/code> and &lt;code>stop&lt;/code> all the project&amp;rsquo;s services:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker stop second_api_1 second_cht-upgrade-service_1 second_couchdb_1 second_haproxy_1 second_healthcheck_1 second_nginx_1 second_sentinel_1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Alternately, you can stop ALL containers (even non-CHT ones!) with &lt;code>docker kill $(docker ps -q)&lt;/code>. Then start the other CHT project using either the &lt;code>.env&lt;/code> file or use the explicit command with ports and other environment variables as shown above.&lt;/p>
&lt;p>To run projects concurrently open a second terminal and start the second project so you don&amp;rsquo;t have to cancel and &lt;code>stop&lt;/code> the first project. Remember to avoid port conflicts!&lt;/p>
&lt;h2 id="cht-docker-helper-for-4x">CHT Docker Helper for 4.x&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
This is for CHT 4.x. To use a CHT 3.x version, see the earlier &lt;a href="https://docs.communityhealthtoolkit.org/hosting/3.x/app-developer/#cht-docker-helper">CHT Docker Helper page&lt;/a>
&lt;/div>
&lt;p>The &lt;code>cht-docker-compose.sh&lt;/code> scripts downloads 3 compose files and builds an &lt;code>.env&lt;/code> file used above. This greatly eases starting your first CHT instance with a simple text based GUI which works on Windows (WSL2), macOS (both x86 and Apple Silicon) and Linux.&lt;/p>
&lt;p>&lt;img src="cht-docker-helper.png" alt="The cht-docker-compose.sh script showing the URL and version of the CHT instance as well as number of containers launched, global container count, medic images downloaded count and OS load average. Finally a &amp;ldquo;Successfully started my_first_project&amp;rdquo; message is shown and denotes the login is &amp;ldquo;medic&amp;rdquo; and the password is &amp;ldquo;password&amp;rdquo;.">&lt;/p>
&lt;p>This script brings a lot of benefits with it:&lt;/p>
&lt;ul>
&lt;li>You only have to download one bash script&lt;/li>
&lt;li>All compose files and images will be downloaded automatically for you&lt;/li>
&lt;li>All networks, storage volumes and containers will be created&lt;/li>
&lt;li>A valid TLS certificate will be installed, allowing you to easily test on with CHT Android natively on a mobile device&lt;/li>
&lt;li>An unused port is automatically chosen for you when creating a new project. No more manually looking at your existing &lt;code>.env&lt;/code> files!&lt;/li>
&lt;/ul>
&lt;h3 id="installing">Installing&lt;/h3>
&lt;p>To get started using it:&lt;/p>
&lt;ol>
&lt;li>Clone the &lt;a href="https://github.com/medic/cht-core/">CHT Core&lt;/a> repo&lt;/li>
&lt;li>When you want to check for updates, just run &lt;code>git pull origin&lt;/code> in the &lt;code>cht-core&lt;/code> directory.&lt;/li>
&lt;/ol>
&lt;p>If you want a more stand-alone version, you can &lt;code>curl&lt;/code> the bash script directly, but you can&amp;rsquo;t use &lt;code>git&lt;/code> to easily update it then:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>curl -s -o cht-docker-compose.sh https://raw.githubusercontent.com/medic/cht-core/master/scripts/docker-helper-4.x/cht-docker-compose.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="usage">Usage&lt;/h3>
&lt;p>Always run the script from the directory where it lives. If you launch it from a different directory, relative paths will fail:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Do&lt;/th>
&lt;th>Don&amp;rsquo;t&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>./cht-docker-compose.sh&lt;/code>&lt;/td>
&lt;td>&lt;code>./docker-helper-4.x/cht-docker-compose.sh&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="launching">Launching&lt;/h4>
&lt;p>Run the script with:&lt;/p>
&lt;pre tabindex="0">&lt;code>./cht-docker-compose.sh
&lt;/code>&lt;/pre>&lt;p>The first time you run, you will be prompted to create a new project. Here&amp;rsquo;s what that looks like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>./cht-docker-compose.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Would you like to initialize a new project &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>y/N&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>? y
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>How &lt;span style="color:#204a87;font-weight:bold">do&lt;/span> you want to name the project? &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span> OH The First
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Downloading compose files ... &lt;span style="color:#204a87;font-weight:bold">done&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Creating network &lt;span style="color:#4e9a06">&amp;#34;4_oh_the_first-cht-net&amp;#34;&lt;/span> with the default driver
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Creating my_first_cht_project-dir_cht-upgrade-service_1 ... &lt;span style="color:#204a87;font-weight:bold">done&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Starting project &lt;span style="color:#4e9a06">&amp;#34;4_oh_the_first&amp;#34;&lt;/span>. First run takes a &lt;span style="color:#204a87;font-weight:bold">while&lt;/span>. Will try &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> up to five minutes........
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> --------------------------------------------------------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Success! &lt;span style="color:#4e9a06">&amp;#34;4_oh_the_first&amp;#34;&lt;/span> is &lt;span style="color:#204a87">set&lt;/span> up:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> https://127-0-0-1.local-ip.medicmobile.org:10444/ &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>CHT&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> https://127-0-0-1.local-ip.medicmobile.org:10444/_utils/ &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>Fauxton&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Login: medic
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Password: password
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> --------------------------------------------------------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Start existing project
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./cht-docker-compose.sh ENV-FILE.env
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Stop and keep project:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./cht-docker-compose.sh ENV-FILE.env stop
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Stop and destroy all project data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ./cht-docker-compose.sh ENV-FILE.env destroy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>https://docs.communityhealthtoolkit.org/apps/guides/hosting/4.x/app-developer/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Have a great day!
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you have many existing projects, you can specify them to launch them directly. If you had a project called &lt;code>4_oh_the_first&lt;/code> you would run:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>./cht-docker-compose.sh 4_oh_the_first.env
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="stopping">Stopping&lt;/h4>
&lt;p>When you&amp;rsquo;re done with a project, it&amp;rsquo;s good to stop all the containers to reduce load on your computer. Do this by specifying the project and the &lt;code>stop&lt;/code> command. This command will simply stop the active Docker containers, and not delete any data. Using our existing example &lt;code>4_oh_the_first&lt;/code> project, you would call:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>./cht-docker-compose.sh 4_oh_the_first.env stop
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="destroying">Destroying&lt;/h4>
&lt;p>When you want to &lt;strong>permanently delete all files and all data&lt;/strong> for a project, specify the project and the &lt;code>destroy&lt;/code> command. Using our existing example &lt;code>4_oh_the_first&lt;/code> project, you would call:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>./cht-docker-compose.sh 4_oh_the_first.env destroy
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Be sure you want to do this, there is no &amp;ldquo;are you sure?&amp;rdquo; prompt and it will delete all your data.&lt;/p>
&lt;p>Also note that this command will use the &lt;code>sudo&lt;/code> command when deleting the CouchDB data, so it may prompt for your password.&lt;/p>
&lt;h4 id="debugging">Debugging&lt;/h4>
&lt;p>To get debug output while running the docker helper, you can prepend the &lt;code>DEBUG=true&lt;/code> flag like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">DEBUG&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">true&lt;/span> ./cht-docker-compose.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This shows load average, CHT container count, global container count, and a table of services with their status like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>---DEBUG INFO---
Load: 3.75 2.92 2.93
CHT Containers: 7
Global Containers 15
Service Status Container Image
cht-upgrade-service running 400_deleteme-dir-cht-upgrade-service-1 public.ecr.aws/s5s3h4s7/cht-upgrade-service:latest
haproxy NA NA public.ecr.aws/medic/cht-haproxy:4.4.0-8229-outbound-push
healthcheck running 400_deleteme_healthcheck_1 public.ecr.aws/medic/cht-haproxy-healthcheck:4.4.0-8229-outbound-push
api running 400_deleteme_api_1 public.ecr.aws/medic/cht-api:4.4.0-8229-outbound-push
sentinel running 400_deleteme_sentinel_1 public.ecr.aws/medic/cht-sentinel:4.4.0-8229-outbound-push
nginx running 400_deleteme_nginx_1 public.ecr.aws/medic/cht-nginx:4.4.0-8229-outbound-push
couchdb running 400_deleteme_couchdb_1 public.ecr.aws/medic/cht-couchdb:4.4.0-8229-outbound-push
&lt;/code>&lt;/pre>&lt;h4 id="troubleshooting">Troubleshooting&lt;/h4>
&lt;p>When you are starting a CHT Core instance using Docker Helper 4.x and don&amp;rsquo;t have any containers created, images downloaded, or storage volumes created - the &lt;code>*.local-ip.medicmobile.org&lt;/code> TLS certificate fails to install, which leads to a browser &lt;code>Your connection is not private&lt;/code> message.&lt;/p>
&lt;p>To solve this issue, follow the steps below:&lt;/p>
&lt;ol>
&lt;li>First, find the name of the &lt;code>nginx&lt;/code> container with: &lt;code>docker ps --filter &amp;quot;name=nginx&amp;quot; --format '{{ .Names }}'&lt;/code>.&lt;/li>
&lt;li>After cloning the &lt;a href="https://github.com/medic/cht-core">CHT Core repo&lt;/a>, &lt;code>cd&lt;/code> into the &lt;code>scripts&lt;/code> directory: &lt;code>cd ./cht-core/scripts&lt;/code>.&lt;/li>
&lt;li>Using the container name from the first command, call the script to update the certificate: &lt;code>./add-local-ip-certs-to-docker-4.x.sh CONTAINER_NAME&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>These three steps look like as following assuming that &lt;code>CONTAINER_NAME&lt;/code> is equal to &lt;code>4_3_0_nginx_1&lt;/code>. Note that &lt;code>CONTAINER_NAME&lt;/code> will be different for each instance of CHT you run with Docker Helper:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ docker ps --filter &amp;#34;name=nginx&amp;#34; --format &amp;#39;{{ .Names }}&amp;#39;
4_3_0_nginx_1
$ cd Documents/MedicMobile/cht-core/scripts/
scripts $ ./add-local-ip-certs-to-docker-4.x.sh 4_3_0_nginx_1
4_3_0_nginx_1
If just container name is shown above, a fresh local-ip.medicmobile.org certificate was downloaded fresh local-ip.medicmobile.org.
&lt;/code>&lt;/pre>&lt;h3 id="file-locations">File locations&lt;/h3>
&lt;p>The bash script keeps files in two places:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;code>*.env&lt;/code> files&lt;/strong> - the same directory as the bash script.&lt;/li>
&lt;li>&lt;strong>&lt;code>~/medic/cht-docker/&lt;/code> files&lt;/strong> - in your home directory, a sub-directory is created for each project. Within each project directory, a &lt;code>compose&lt;/code> directory has the two compose files and the &lt;code>couch&lt;/code> directory has the CouchDB datafiles.&lt;/li>
&lt;/ul>
&lt;p>While you can manually remove any of these, it&amp;rsquo;s best to use the &lt;code>destroy&lt;/code> command above to ensure all related data files are deleted too.&lt;/p>
&lt;h3 id="video">Video&lt;/h3>
&lt;p>Here is a video of the helper being run on 1 Dec 2022. The video references &lt;code>lazydocker&lt;/code> which is &lt;a href="https://github.com/jesseduffield/lazydocker">a great way&lt;/a> to monitor and control your local docker environment:&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/hrcy8JlJP9M" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;hr></description></item><item><title>Hosting: Adding TLS certificates in CHT 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/adding-tls-certificates/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/adding-tls-certificates/</guid><description>
&lt;p>By default, CHT 4.x will create a self-signed certificate for every deployment. These instructions are for changing to either a pre-existing certificate or automatically creating and renewing a &lt;a href="https://certbot.eff.org/">Certbot&lt;/a> based certificate using &lt;a href="https://acmeclients.com/">ACME&lt;/a>, like &lt;a href="https://letsencrypt.org/">Let&amp;rsquo;s Encrypt&lt;/a>.&lt;/p>
&lt;p>This guide assumes you&amp;rsquo;ve already met the &lt;a href="https://docs.communityhealthtoolkit.org/hosting/requirements/">hosting requirements&lt;/a>, specifically around Docker being installed.&lt;/p>
&lt;h2 id="pre-existing-certificate">Pre-existing certificate&lt;/h2>
&lt;p>To load your certificates into your CHT instance, we&amp;rsquo;ll be creating an interstitial container called &lt;code>cht-temp-tls&lt;/code> which will enable you to copy your local certificate files into the native docker volume.&lt;/p>
&lt;h3 id="prerequisites">Prerequisites&lt;/h3>
&lt;p>You have two files locally on your workstation in the directory you&amp;rsquo;re currently in:&lt;/p>
&lt;ul>
&lt;li>&lt;code>key.pem&lt;/code> - the private key for your TLS certificate&lt;/li>
&lt;li>&lt;code>cert.pem&lt;/code> - both the public and any interstitial keys concatenated into one file&lt;/li>
&lt;/ul>
&lt;p>Also, be sure you have started your CHT instance once and all your volumes are created.&lt;/p>
&lt;h3 id="loading-the-certificate">Loading the certificate&lt;/h3>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
&lt;code>docker compose&lt;/code> should work, but you may need to use the older style &lt;code>docker-compose&lt;/code> if you get an error &lt;code>docker: 'compose' is not a docker command&lt;/code>.
&lt;/div>
&lt;ol>
&lt;li>
&lt;p>Find the name of your &lt;code>cht-ssl&lt;/code> volume with this call:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker volume ls --filter &lt;span style="color:#4e9a06">&amp;#34;name=cht-ssl&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It is very likely that &lt;code>cht_cht-ssl&lt;/code> is the name of our &lt;code>cht-ssl&lt;/code> volume.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Using the volume name found in step 1, start a container called &lt;code>temp&lt;/code> which allow us to copy files into the docker volume:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker run -d --rm --name temp -v cht_cht-ssl:/etc/nginx/private/ alpine tail -f /dev/null
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Copy the two pem files into the volume via the temporary container:&lt;/p>
&lt;pre tabindex="0">&lt;code>docker cp key.pem temp:/etc/nginx/private/.
docker cp cert.pem temp:/etc/nginx/private/.
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Stop the &lt;code>temp&lt;/code> container:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker &lt;span style="color:#204a87">kill&lt;/span> temp
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;p>Your certificates are now safely stored in the native docker volume. Restart your CHT instance the way you started it, being sure to set the correct &lt;code>CERTIFICATE_MODE&lt;/code> and &lt;code>SSL_VOLUME_MOUNT_PATH&lt;/code> per the &lt;a href="#prerequisites">prerequisites&lt;/a>.&lt;/p>
&lt;h2 id="certbot-certificate">Certbot certificate&lt;/h2>
&lt;p>&lt;em>This Feature available on CHT 4.2.0 or later&lt;/em>&lt;/p>
&lt;p>If you have a deployment with a static, public IP and a domain name pointing to that IP, you can have Certbot automatically create free TLS certificates by using &lt;a href="https://hub.docker.com/r/certbot/certbot/">their Docker image&lt;/a>.&lt;/p>
&lt;p>Assuming your CHT instance is running with the default self signed cert. Be sure to change &lt;code>cht.example.com&lt;/code> to your domain first though:&lt;/p>
&lt;p>Assuming your CHT instance is &lt;strong>already running with the default self-signed cert&lt;/strong>:&lt;/p>
&lt;ol>
&lt;li>Edit the CHT&amp;rsquo;s environment file at &lt;code>/home/ubuntu/cht/upgrade-service/.env&lt;/code> so this line is present:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">CERTIFICATE_MODE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>AUTO_GENERATE
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>This will ensure the &lt;code>deploy.sh&lt;/code> script that certbot uses to deploy the certificates is available for use.&lt;/li>
&lt;li>Restart your CHT instance to ensure the new &lt;code>CERTIFICATE_MODE&lt;/code> value takes effect:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> /home/ubuntu/cht/upgrade-service/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker stop &lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>docker ps --filter &lt;span style="color:#4e9a06">&amp;#34;name=^cht*&amp;#34;&lt;/span> -q&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker stop &lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>docker ps --filter &lt;span style="color:#4e9a06">&amp;#34;name=^upgrade-service*&amp;#34;&lt;/span> -q&lt;span style="color:#204a87;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker compose up --detach
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Create certbot compose and env files by copying and pasting this code:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p /home/ubuntu/cht/certbot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> /home/ubuntu/cht/certbot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cat &amp;gt; docker-compose.yml &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">version: &amp;#39;3.9&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">services:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> certbot:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> container_name: certbot
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> hostname: certbot
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> image: certbot/certbot
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> volumes:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> - ssl-storage:/etc/nginx/private/
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> - ssl-storage:/var/log/letsencrypt/
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> command: certonly --debug --deploy-hook /etc/nginx/private/deploy.sh --webroot -w /etc/nginx/private/certbot/ --domain \$DOMAIN --non-interactive --key-type rsa --agree-tos --register-unsafely-without-email \$STAGING
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">volumes:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> ssl-storage:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> name: \${CHT_SSL_VOLUME}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06"> external: true
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cat &amp;gt; .env &lt;span style="color:#4e9a06">&amp;lt;&amp;lt; EOF
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">DOMAIN=cht.example.com
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">STAGING=
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">CHT_SSL_VOLUME=cht_cht-ssl
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">TZ=America/Whitehorse
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>Certbot only lets you create the identical certificates 5 times per 7 days. If you&amp;rsquo;re unsure of how this works you can change &lt;code>STAGING=&lt;/code> to &lt;code>STAGING=--staging&lt;/code> in the &lt;code>/home/ubuntu/cht/certbot/.env&lt;/code> file to do repeated tests. Be sure to change this back to &lt;code>STAGING=&lt;/code> when you&amp;rsquo;re ready to create production certificates.&lt;/li>
&lt;li>Generate certs:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#204a87">cd&lt;/span> /home/ubuntu/cht/certbot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker compose up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Run this command to find the name of your CHT ngnix container:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker ps --filter &lt;span style="color:#4e9a06">&amp;#34;name=nginx&amp;#34;&lt;/span> --format &lt;span style="color:#4e9a06">&amp;#39;{{ .Names }}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Assuming the name is &lt;code>cht_nginx_1&lt;/code> from the prior step, reload your &lt;code>nginx&lt;/code> config with this command:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker &lt;span style="color:#204a87">exec&lt;/span> -it cht_nginx_1 nginx -s reload
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Attempt to renew your certificates once a week by adding this cronjob via &lt;code>crontab -e&lt;/code>. Certbot will only renew them as needed:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> * * &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#204a87">cd&lt;/span> /home/ubuntu/cht/certbot&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span>docker compose up
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h2 id="troubleshooting">Troubleshooting&lt;/h2>
&lt;h3 id="proxying">Proxying&lt;/h3>
&lt;h4 id="err_tls_cert_altname_invalid">ERR_TLS_CERT_ALTNAME_INVALID&lt;/h4>
&lt;p>When proxying to HTTPS from HTTP (for example where an ingress does TLS termination in an SNI environment and then the traffic is proxied to an HTTPS service (eg, haproxy)), not including a &lt;code>servername&lt;/code> for a request to the HTTPS server (eg, def.org) produces the following error:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">&amp;#39;ERR_TLS_CERT_ALTNAME_INVALID&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">&amp;#34;RequestError: Error [ERR_TLS_CERT_ALTNAME_INVALID]: Hostname/IP does not match certificate&amp;#39;s altnames:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#4e9a06">Host: abc.com. is not in the cert&amp;#39;s altnames: DNS:def.org&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The addition of &lt;code>servername&lt;/code> resolves this error by providing routing information. See &lt;a href="https://nodejs.org/api/tls.html">docs&lt;/a> for &lt;code>tls.connect(options[, callback])&lt;/code>: &amp;ldquo;Server name for the SNI (Server Name Indication) TLS extension. It is the name of the host being connected to, and must be a host name, and not an IP address.&amp;rdquo;.&lt;/p>
&lt;p>A &lt;code>servername&lt;/code> parameter may be added to all requests to the haproxy/couchdb by setting the environment variable &lt;code>ADD_SERVERNAME_TO_HTTP_AGENT&lt;/code> to &lt;code>true&lt;/code>.&lt;/p>
&lt;p>A similar change can be made for the http clients used in the application by setting &lt;code>PROXY_CHANGE_ORIGIN&lt;/code> to &lt;code>true&lt;/code>. This sets the &lt;code>changeOrigin&lt;/code> parameter of all the &lt;code>http-proxy&lt;/code> clients to &lt;code>true&lt;/code>, which &amp;ldquo;changes the origin of the host header to the target URL&amp;rdquo;. See &lt;a href="https://www.npmjs.com/package/http-proxy#options">http-proxy: options&lt;/a>.&lt;/p></description></item><item><title>Hosting: Viewing server logs in CHT 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/logs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/logs/</guid><description>
&lt;p>CHT 4.x has the following services running via Docker and each can have its logs queried:&lt;/p>
&lt;ul>
&lt;li>nginx&lt;/li>
&lt;li>sentinel&lt;/li>
&lt;li>api&lt;/li>
&lt;li>haproxy&lt;/li>
&lt;li>couchdb&lt;/li>
&lt;li>healthcheck&lt;/li>
&lt;li>upgrade-service&lt;/li>
&lt;/ul>
&lt;h2 id="setting-log-level">Setting log level&lt;/h2>
&lt;p>By default, the CHT server logs are set to the &lt;code>info&lt;/code> level. To change the log level to &lt;code>debug&lt;/code>, you can set the &lt;code>NODE_ENV&lt;/code> environment variable to &lt;code>development&lt;/code>. A log level of &lt;code>debug&lt;/code> can affect system performance and cause log files sizes to grow rapidly. It is recommended to temporarily set the log level to &lt;code>debug&lt;/code> only when needed for troubleshooting.&lt;/p>
&lt;h2 id="viewing-logs">Viewing logs&lt;/h2>
&lt;p>First, find the actual names of the containers with the &lt;code>docker ps --format '{{.Names}}'&lt;/code> command which should show something like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>cht_nginx_1
cht_sentinel_1
cht_api_1
cht_haproxy_1
cht_healthcheck_1
cht_couchdb_1
upgrade-service-cht-upgrade-service-1
&lt;/code>&lt;/pre>&lt;p>You can then use the &lt;code>docker logs&lt;/code> command to view the logs of any given container. For example, if we call &lt;code>docker logs cht_nginx_1&lt;/code> it will show ALL the logs from that container. To show only the last 5 lines, you can use the &lt;code>--tail&lt;/code> flag to specify the number of lines like this &lt;code>docker logs cht_nginx_1 --tail 5&lt;/code>. The result will look like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>10.131.161.1 - - [15/Feb/2023:21:08:35 +0000] &amp;#34;GET /medic/_changes?feed=longpoll&amp;amp;heartbeat=10000&amp;amp;since=115-g1AAAAH5eJyF0LENwjAQBVCLRIAEFBTMgESBCA0lrACJBzgnRXSKoKJmClaAxEswRZbIDCTHZ4GzXPzCT-d_rowx8zIqzDK_3fOycKdkf9jucJIKVyMybmVtxhQp6E-s23jfME00B-LdUWQIOBBxmJkG3gXJHHtfM8WaA2ncQ6RnGmsOZLjG5mLtk2mmSKAUCPHGSkxT3dZAiK_IR28A1AMhzta2wbko2iJe3ndMC92iaIfAzwrTmn8as5aY&amp;amp;limit=25 HTTP/1.1&amp;#34; 499 0 &amp;#34;https://10-131-161-159.local-ip.medicmobile.org/&amp;#34; &amp;#34;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0&amp;#34;
10.131.161.1 - - [15/Feb/2023:21:08:35 +0000] &amp;#34;GET /medic-user-medic-meta/_changes?include_docs=true&amp;amp;feed=longpoll&amp;amp;heartbeat=10000&amp;amp;since=13-g1AAAAH5eJyF0LENwkAMhWETKGkoWIICERpKWAESD3BOiugUQUXNFKwAiZdgiiyRGUjMY4FYV_zFfbJ8VxPRspqXtCpu96Iq5ZTuD9sdTlrjKgkka-Y8htkE-hOWjWrrOBCVo9noOBATzMwcB5JLVG0cB9LKw2xwHMh4XdCF-TktgTIg5I0nubYBQr5mnxiSaTsAIWfmzp2LRTvkpdq7Fov2CH7WYOMP5CCWMg&amp;amp;limit=25 HTTP/1.1&amp;#34; 499 0 &amp;#34;https://10-131-161-159.local-ip.medicmobile.org/&amp;#34; &amp;#34;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0&amp;#34;
10.131.161.1 - - [15/Feb/2023:21:08:35 +0000] &amp;#34;GET /fontawesome-webfont.woff2 HTTP/1.1&amp;#34; 304 0 &amp;#34;https://10-131-161-159.local-ip.medicmobile.org/styles.css&amp;#34; &amp;#34;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0&amp;#34;
10.131.161.1 - - [15/Feb/2023:21:08:35 +0000] &amp;#34;GET /fonts/NotoSans-Bold.ttf HTTP/1.1&amp;#34; 304 0 &amp;#34;https://10-131-161-159.local-ip.medicmobile.org/styles.css&amp;#34; &amp;#34;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0&amp;#34;
10.131.161.1 - - [15/Feb/2023:21:08:35 +0000] &amp;#34;GET /fonts/NotoSans-Regular.ttf HTTP/1.1&amp;#34; 200 221787 &amp;#34;https://10-131-161-159.local-ip.medicmobile.org/styles.css&amp;#34; &amp;#34;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0
&lt;/code>&lt;/pre>&lt;p>Sometimes you may want to search the logs for a specific string. To search, use the pipe (&lt;code>|&lt;/code>) and &lt;code>grep&lt;/code> commands to do this. Here we search for all the times HA Proxy thought CouchDB wasn&amp;rsquo;t reachable (&lt;code>DOWN&lt;/code>) with this call &lt;code>docker logs cht_haproxy_1 2&amp;gt;&amp;amp;1 | grep 'DOWN'&lt;/code>:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;145&amp;gt;Feb 15 20:52:06 haproxy[25]: Server couchdb-servers/couchdb is DOWN, reason: Layer7 wrong status, code: 0, info: &amp;#34;via agent : down&amp;#34;, check duration: 208ms. 0 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.
[WARNING] 045/205206 (25) : Server couchdb-servers/couchdb is DOWN, reason: Layer7 wrong status, code: 0, info: &amp;#34;via agent : down&amp;#34;, check duration: 208ms. 0 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.
[WARNING] 045/205601 (25) : Server couchdb-servers/couchdb is DOWN, reason: Layer7 wrong status, code: 0, info: &amp;#34;via agent : down&amp;#34;, check duration: 207ms. 0 active and 0 backup servers left. 5 sessions active, 0 requeued, 0 remaining in queue.
&amp;lt;145&amp;gt;Feb 15 20:56:01 haproxy[25]: Server couchdb-servers/couchdb is DOWN, reason: Layer7 wrong status, code: 0, info: &amp;#34;via agent : down&amp;#34;, check duration: 207ms. 0 active and 0 backup servers left. 5 sessions active, 0 requeued, 0 remaining in queue.
&lt;/code>&lt;/pre>&lt;p>If you want to watch the logs for a specific container in real time, you can use the &lt;code>--follow&lt;/code> flag. This command would watch the requests come into API in realtime: &lt;code>docker logs cht_api_1 --follow&lt;/code>. It&amp;rsquo;s nice to couple this with the &lt;code>--tail&lt;/code> command so you only see the last 5 lines of the existing logs before watching for new lines with &lt;code>docker logs cht_api_1 --follow --tail 5&lt;/code> which would show this:&lt;/p>
&lt;pre tabindex="0">&lt;code>RES d17d71f5-2dcb-4ebb-bb0e-7874b3000570 10.131.161.1 - GET /medic/_design/medic-client/_view/reports_by_subject?keys=%5B%22557e79b8-2d99-4bd1-a4d6-a44491d483d8%22%5D HTTP/1.0 200 - 12.452 ms
RES e43c5d7f-4e32-433a-a96d-ef991f4298a3 10.131.161.1 - GET /medic/_design/medic/_view/doc_summaries_by_id?keys=%5B%22557e79b8-2d99-4bd1-a4d6-a44491d483d8%22%5D HTTP/1.0 200 - 31.226 ms
REQ c656ecc7-e6af-4564-ad63-2cab2c42844a 10.131.161.1 - GET /medic/_all_docs?include_docs=true&amp;amp;startkey=%22target~2023-02~557e79b8-2d99-4bd1-a4d6-a44491d483d8~%22&amp;amp;endkey=%22target~2023-02~557e79b8-2d99-4bd1-a4d6-a44491d483d8~%EF%BF%B0%22 HTTP/1.0
RES c656ecc7-e6af-4564-ad63-2cab2c42844a 10.131.161.1 - GET /medic/_all_docs?include_docs=true&amp;amp;startkey=%22target~2023-02~557e79b8-2d99-4bd1-a4d6-a44491d483d8~%22&amp;amp;endkey=%22target~2023-02~557e79b8-2d99-4bd1-a4d6-a44491d483d8~%EF%BF%B0%22 HTTP/1.0 200 - 11.153 ms
2023-02-15 21:54:49 DEBUG: Checking for a configured outgoing message service
&lt;/code>&lt;/pre></description></item><item><title>Hosting: Backups in CHT 4.x</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/backups/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/backups/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>This guide is about backups in CHT 4.x - there&amp;rsquo;s the &lt;a href="https://docs.communityhealthtoolkit.org/hosting/3.x/self-hosting/#backup">self hosted guide for 3.x&lt;/a> which includes backups for 3.x.&lt;/p>
&lt;/div>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>As CHT 4.x uses a container per service, the only data that needs to be backed up is:&lt;/p>
&lt;ul>
&lt;li>CouchDB database&lt;/li>
&lt;li>Docker Compose and &lt;code>.env&lt;/code> files&lt;/li>
&lt;li>TLS certificates&lt;/li>
&lt;/ul>
&lt;p>This is because Docker containers are inherently stateless so all the important binaries are already stored in &lt;a href="https://gallery.ecr.aws/s5s3h4s7/">CHT&amp;rsquo;s Docker images&lt;/a>. Docker Compose files, including the &lt;code>.env&lt;/code> file, store all of your deployment&amp;rsquo;s configuration. Finally, the TLS certificates should be backed up to reduce recovery time.&lt;/p>
&lt;p>How to backup each of these three pieces of data is covered below.&lt;/p>
&lt;p>Therefore, you do &lt;strong>not&lt;/strong> need to back up the docker images for:&lt;/p>
&lt;ul>
&lt;li>nginx&lt;/li>
&lt;li>sentinel&lt;/li>
&lt;li>api&lt;/li>
&lt;li>haproxy&lt;/li>
&lt;li>couchdb&lt;/li>
&lt;li>healthcheck&lt;/li>
&lt;li>upgrade-service&lt;/li>
&lt;/ul>
&lt;h2 id="assumptions">Assumptions&lt;/h2>
&lt;p>This guide assumes you have an Ubuntu server running CHT 4.x in Docker as described in our &lt;a href="https://docs.communityhealthtoolkit.org/hosting/4.x/self-hosting/single-node/">Self Hosting in CHT 4.x - Single CouchDB Node&lt;/a> guide. If you run &lt;code>docker ps --format '{{.Names}}'&lt;/code> you should see something like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>cht_nginx_1
cht_sentinel_1
cht_api_1
cht_haproxy_1
cht_healthcheck_1
cht_couchdb_1
upgrade-service-cht-upgrade-service-1
&lt;/code>&lt;/pre>&lt;p>If you run &lt;code>docker volume ls&lt;/code> you should see something like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>DRIVER VOLUME NAME
local cht_cht-credentials
local cht_cht-ssl
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Note&lt;/strong> - In the volumes listed above, there is no volume for CouchDB data. This is because the compose file declares this as a &lt;a href="https://docs.docker.com/storage/bind-mounts/">bind mount&lt;/a>. Bind mounts use the host file system directly and do not show up in &lt;code>docker volume ls&lt;/code> calls. It&amp;rsquo;s therefore assumed your CouchDB data location is declared in &lt;code>/home/ubuntu/cht/upgrade-service/.env&lt;/code> which sets it with &lt;code>COUCHDB_DATA=/home/ubuntu/cht/couchdb&lt;/code>.&lt;/p>
&lt;p>You should have SSH access to the server with &lt;code>root&lt;/code> access.&lt;/p>
&lt;h3 id="backup-software">Backup software&lt;/h3>
&lt;p>It&amp;rsquo;s assumed you are using which ever tool you&amp;rsquo;re familiar with which might include &lt;a href="https://rsync.samba.org/examples.html">rsync&lt;/a>, &lt;a href="https://borgbackup.readthedocs.io/en/stable/">borg&lt;/a>, &lt;a href="https://duplicity.gitlab.io/">duplicity&lt;/a> or other solution. The locations of the backups should follow the 3-2-1 rule:&lt;/p>
&lt;blockquote>
&lt;p>There should be at least 3 copies of the data, stored on 2 different types of storage media, and one copy should be kept offsite, in a remote location. &lt;em>- &lt;a href="https://en.wikipedia.org/wiki/Backup">Wikipedia&lt;/a>&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;p>Duplicity has the handy benefit of offering built in encryption using &lt;a href="https://gnupg.org/">GPG&lt;/a>. Consider using this if you don&amp;rsquo;t have an existing solution for encrypted backups.&lt;/p>
&lt;h2 id="couchdb">CouchDB&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
CouchDB backups, by necessity, will have PII and PHI. They should be safely stored to prevent unauthorized access including encrypting backups.
&lt;/div>
&lt;p>Assuming your CouchDB is stored in &lt;code>/home/ubuntu/cht/couchdb&lt;/code>, you should use these steps to back it up:&lt;/p>
&lt;ol>
&lt;li>While you don&amp;rsquo;t need to stop CouchDB to back it up, ensure you follow best practices to back it up. See the &lt;a href="https://docs.couchdb.org/en/stable/maintenance/backups.html">CouchDB site&lt;/a> for more info. Note that Medic recommends NOT using replication for backup.&lt;/li>
&lt;li>It is strongly recommended you encrypt your backups given the sensitivity of the contents. Do this now before copying the backup files to their long term location.&lt;/li>
&lt;li>Backup the CouchDB files using the &lt;a href="#backup-software">software specified above&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="docker-compose-files">Docker Compose files&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
The &lt;code>.env&lt;/code> file contains cleartext passwords. It should be safely stored to prevent unauthorized access.
&lt;/div>
&lt;p>All compose files, and the corresponding &lt;code>.env&lt;/code> file, are in these three locations:&lt;/p>
&lt;ul>
&lt;li>/home/ubuntu/cht/compose/*.yml&lt;/li>
&lt;li>/home/ubuntu/cht/upgrade-service/*.yml&lt;/li>
&lt;li>/home/ubuntu/cht/upgrade-service/.env&lt;/li>
&lt;/ul>
&lt;p>While all three of these are trivial to recreate by downloading them again, they may change over time so should be archived with your CouchDB data. Further, when there&amp;rsquo;s been a critical failure of a production CHT instance, you want to be sure to make the restore process as speedy as possible.&lt;/p>
&lt;p>As all of these files are only read when Docker first loads a service, you can simply copy them whenever you want without stopping any of the CHT services. They should be copied with the same frequency and put in the same location as the CouchDB data using the &lt;a href="#backup-software">backup software specified above&lt;/a>.&lt;/p>
&lt;h2 id="tls-certificates">TLS certificates&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
The &lt;code>.key&lt;/code> file is the private key for TLS certificate. It should be safely stored to prevent unauthorized access.
&lt;/div>
&lt;p>Like the compose files, the TLS certificate files can easily be regenerated or re-downloaded from your Certificate Authority, like Let&amp;rsquo;s Encrypt for example. However, you want to have a backup of the at the ready to ease the restore process.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Copy the cert and key files from the nginx container:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>docker cp cht_nginx_1:/etc/nginx/private/key.pem .
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker cp cht_nginx_1:/etc/nginx/private/cert.pem .
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Back the up to the same location and frequency as the CouchDB data using the &lt;a href="#backup-software">backup software specified above&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="testing-backups">Testing backups&lt;/h2>
&lt;p>A backup that isn&amp;rsquo;t tested, is effectively not a backup. For a backup to be successful, a complete restore from all locations in the 3-2-1 plan need to be fully tested and documented as to how a restore works. The more practiced and better documented the restore process, the less downtime a production CHT instance will have after data loss.&lt;/p></description></item><item><title>Hosting: Docker Directory Setup</title><link>https://docs.communityhealthtoolkit.org/hosting/4.x/_partial_docker_directories/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/hosting/4.x/_partial_docker_directories/</guid><description>
&lt;p>Create the following directory structure:&lt;/p>
&lt;pre tabindex="0">&lt;code>|-- /home/ubuntu/cht/
|-- compose/
|-- certs/
|-- couchdb/
|-- upgrade-service/
&lt;/code>&lt;/pre>&lt;p>By calling this &lt;code>mkdir&lt;/code> commands:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mkdir -p /home/ubuntu/cht/&lt;span style="color:#ce5c00;font-weight:bold">{&lt;/span>compose,certs,upgrade-service,couchdb&lt;span style="color:#ce5c00;font-weight:bold">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol>
&lt;li>&lt;code>compose&lt;/code> - docker-compose files for cht-core and CouchDB&lt;/li>
&lt;li>&lt;code>certs&lt;/code> - TLS certificates directory&lt;/li>
&lt;li>&lt;code>upgrade-service&lt;/code> - where docker-compose file for the upgrade-service&lt;/li>
&lt;li>&lt;code>couchdb&lt;/code> - the path for the docker-compose file of the upgrade-service (not used in multi-node)&lt;/li>
&lt;/ol></description></item></channel></rss>